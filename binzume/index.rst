Androidのカメラで物体の奥行情報取得(仮)
****************************************

書けない気がします．査読頑張ります．


こんにちは，binzumeです．

今回のななかInside PRESSのテーマは「Immutable Infrastructure」らしいですね．よくわからないですがDocker便利とか便利ですよね！

という流れを無視して，Androidのカメラを使った実験的なアプリについて書こうと思います．
上手く行ったらサービス作りたいのですが，色々試した感じではそんなに甘くはなく，あくまで「実験的」と先に断わっておきます．

はじめに
===============================

最近はVR流行ってますね．

書く：スマートフォンで，周りの環境の3Dモデルを取り込む話．

書く：Google の Project Tangoとかの話．


画像から物体の3D形状を推定するために，多くの場合，複数の視点から見た画像を入力として処理しますが，カメラが2つ以上必要か，もしくはカメラを移動して2回画像を取得しないといけないのがネック(？)です．


方針
-----------------------------

他の方法として，フォーカス機構のあるカメラならカメラを動かさなくても，フォーカスを変えながら撮った画像を使えば，奥行きの情報が得られそうなので試してみました．

AndroidのカメラAPIにはマニュアルフォーカスが無いので，FOCUS_MODE_INFINITYにした状態からFOCUS_MODE_AUTOにした時にプレビュー画像を連続で処理することで無理やりどうにかします．




アプリを作る
===============================

スマートフォンのカメラのオートフォーカスの仕組み
-------------------------------------------------

レンズとか電磁石とか画像処理とか．


画像の情報量について書く？
-----------------------------

アルゴリズムの話
-----------------------------

フォーカスを合わせるのにかかる時間は長くて1秒．
その間に10枚程度は画像を取得できる．

適当なサイズのブロック単位で情報量のピークを出す．

精度を上げる話．

fuga
^^^^^



まとめ
===============================

前から試してみようと温めてきたネタですが，作ってみて実用的では無い感じだったので，せめて，記事としてまとめておこうと．


コードはGitHubに置きます．


